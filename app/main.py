import streamlit as st
import requests
from faster_whisper import WhisperModel
from pathlib import Path

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –±–µ–∑ –ª–∏—à–Ω–∏—Ö –º–∏–≥–∞—é—â–∏—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤
st.set_page_config(page_title="AI Transcriber", layout="wide")
st.title("–¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è –∏ AI –ê–Ω–∞–ª–∏–∑")

OLLAMA_URL = "http://ollama:11434"
DATA_DIR = Path("/data")

@st.cache_resource
def load_whisper():
    return WhisperModel("medium", device="cpu", compute_type="int8")

def query_ollama(prompt, language):
    MODEL_NAME = "llama3.2:3b"

    # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ç—Ä–æ–≥–æ–µ —É–∫–∞–∑–∞–Ω–∏–µ —è–∑—ã–∫–∞ –≤ –ø—Ä–æ–º–ø—Ç
    lang_instruction = "–û—Ç–≤–µ—á–∞–π —Ç–æ–ª—å–∫–æ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ." if language == "–†—É—Å—Å–∫–∏–π" else "Respond only in English."

    full_prompt = f"{lang_instruction}\n\n–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ç–µ–∫—Å—Ç –Ω–∏–∂–µ. –í—ã–¥–µ–ª–∏ –≥–ª–∞–≤–Ω—É—é –º—ã—Å–ª—å –∏ 3-5 –∫–ª—é—á–µ–≤—ã—Ö –º–æ–º–µ–Ω—Ç–æ–≤.\n\n–¢–µ–∫—Å—Ç:\n{prompt}"

    try:
        response = requests.post(
            f"{OLLAMA_URL}/api/generate",
            json={
                "model": MODEL_NAME,
                "prompt": full_prompt,
                "stream": False
            },
            timeout=120
        )
        return response.json().get("response", "–û—à–∏–±–∫–∞: –Ω–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Ç–µ–∫—Å—Ç –æ—Ç AI")
    except Exception as e:
        return f"–û—à–∏–±–∫–∞ —Å–≤—è–∑–∏ —Å Ollama: {str(e)}"

# --- –¢–†–ê–ù–°–ö–†–ò–ë–ê–¶–ò–Ø ---
uploaded_file = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ –≤–∏–¥–µ–æ –∏–ª–∏ –∞—É–¥–∏–æ", type=['mov', 'mp4', 'mp3', 'wav', 'm4a'])

if uploaded_file:
    input_path = DATA_DIR / uploaded_file.name
    with open(input_path, "wb") as f:
        f.write(uploaded_file.getbuffer())

    if st.button("üöÄ 1. –ù–∞—á–∞—Ç—å —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—é", use_container_width=True):
        model = load_whisper()
        progress_bar = st.progress(0)

        segments, info = model.transcribe(str(input_path), language="ru")

        full_text = ""
        for s in segments:
            full_text += s.text.strip() + " "
            progress_bar.progress(min(s.end / info.duration, 1.0))

        st.session_state['text'] = full_text
        st.success("–¢–µ–∫—Å—Ç —É—Å–ø–µ—à–Ω–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω")

# --- –ê–ù–ê–õ–ò–ó ---
if 'text' in st.session_state:
    st.divider()

    col_text, col_settings = st.columns([2, 1])

    with col_text:
        text_area = st.text_area("–†–µ–∑—É–ª—å—Ç–∞—Ç —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏:", value=st.session_state['text'], height=300)

    with col_settings:
        st.subheader("–ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∞–Ω–∞–ª–∏–∑–∞")
        # –í—ã–±–æ—Ä —è–∑—ã–∫–∞ –¥–ª—è Ollama
        target_lang = st.selectbox("–Ø–∑—ã–∫ –æ—Ç–≤–µ—Ç–∞ AI:", ["–†—É—Å—Å–∫–∏–π", "–ê–Ω–≥–ª–∏–π—Å–∫–∏–π"])

        if st.button("üß† 2. –ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ç–µ–∫—Å—Ç", use_container_width=True):
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—ã—á–Ω—ã–π spinner, –æ–Ω –≤—ã–≥–ª—è–¥–∏—Ç –∞–∫–∫—É—Ä–∞—Ç–Ω–µ–µ
            with st.spinner('AI –≥–æ—Ç–æ–≤–∏—Ç —Å–∞–º–º–∞—Ä–∏...'):
                result = query_ollama(text_area, target_lang)
                st.session_state['analysis'] = result

    if 'analysis' in st.session_state:
        st.markdown("---")
        st.subheader("üìã –ò—Ç–æ–≥–∏ –∞–Ω–∞–ª–∏–∑–∞")
        st.info(st.session_state['analysis'])

        # –ö–Ω–æ–ø–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
        st.download_button(
            label="üì• –°–∫–∞—á–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞",
            data=st.session_state['analysis'],
            file_name=f"analysis_{target_lang}.txt",
            mime="text/plain"
        )