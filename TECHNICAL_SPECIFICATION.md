# Техническое задание (ТЗ) на разработку системы "AI Transcriber"

## 1. Общие сведения
**Название проекта:** AI Transcriber  
**Цель проекта:** Создание веб-приложения для автоматической транскрибации аудио/видео файлов и последующего интеллектуального анализа текста с использованием локальных нейросетей.

## 2. Архитектура системы
Система строится на микросервисной архитектуре с использованием Docker Compose и состоит из двух основных контейнеров:

### 2.1. Сервис приложения (Whisper App)
*   **Технологический стек:** Python 3.9+, Streamlit.
*   **Основные библиотеки:** `faster-whisper`, `requests`, `streamlit`.
*   **Функции:**
    *   Предоставление пользовательского интерфейса.
    *   Обработка загрузки файлов.
    *   Выполнение транскрибации (Speech-to-Text).
    *   Взаимодействие с сервисом Ollama для анализа текста.

### 2.2. Сервис AI-анализа (Ollama Service)
*   **Технологический стек:** Ollama.
*   **Модель:** `llama3.2:3b` (автоматическая загрузка при старте).
*   **Функции:**
    *   Предоставление API для генерации текста.
    *   Обработка запросов на анализ и суммаризацию.

## 3. Функциональные требования

### 3.1. Загрузка данных
*   Пользователь должен иметь возможность загружать файлы через веб-интерфейс.
*   **Поддерживаемые форматы:** `.mov`, `.mp4`, `.mp3`, `.wav`, `.m4a`.
*   Файлы сохраняются в локальную директорию `/data` для обработки.

### 3.2. Транскрибация (Speech-to-Text)
*   Использование модели `faster-whisper` (конфигурация: `medium`, device=`cpu`, compute_type=`int8`).
*   Отображение прогресс-бара во время обработки.
*   Язык транскрибации по умолчанию: Русский (`ru`).
*   Вывод распознанного текста в редактируемое поле.

### 3.3. Анализ текста (AI Analysis)
*   Возможность редактирования текста перед отправкой на анализ.
*   **Настройки анализа:**
    *   Выбор языка ответа модели (Русский / Английский).
*   **Промпт для модели:**
    *   Анализ текста.
    *   Выделение главной мысли.
    *   Выделение 3-5 ключевых моментов.
*   Отображение индикатора загрузки ("AI готовит саммари...").

### 3.4. Экспорт результатов
*   Отображение итогов анализа в отдельном блоке.
*   Возможность скачивания результата анализа в текстовом файле (`.txt`).

## 4. Технические требования

### 4.1. Среда выполнения
*   Docker и Docker Compose.
*   Поддержка архитектуры ARM (Apple Silicon) и x86_64.

### 4.2. Конфигурация Docker Compose
*   **Сервис `whisper`:**
    *   Порт: `8501` (доступ к UI).
    *   Volume: `./data:/data` (обмен файлами).
    *   Зависимость: `depends_on: ollama`.
*   **Сервис `ollama`:**
    *   Порт: `11434` (внутренний API).
    *   Volume: `./data/ollama:/root/.ollama` (кеш моделей).
    *   Автоматический `pull` модели `llama3.2:3b` при запуске.

### 4.3. Производительность
*   Использование квантования `int8` для Whisper для оптимизации работы на CPU.
*   Таймаут ожидания ответа от Ollama: 120 секунд.

## 5. Интерфейс пользователя (UI/UX)
*   **Фреймворк:** Streamlit.
*   **Макет:** Широкоформатный (`layout="wide"`).
*   **Элементы:**
    *   Заголовок "AI Transcriber".
    *   Виджет загрузки файлов (`file_uploader`).
    *   Кнопка "Начать транскрибацию".
    *   Текстовое поле с результатом транскрибации.
    *   Панель настроек анализа (выбор языка).
    *   Кнопка "Анализировать текст".
    *   Блок с результатами анализа.
    *   Кнопка скачивания отчета.

## 6. План развития (Optional)
*   Добавление поддержки GPU для ускорения транскрибации.
*   Поддержка выбора модели Whisper (tiny, base, small, large) из UI.
*   Добавление диаризации (разделения по спикерам).
*   История обработанных файлов.
